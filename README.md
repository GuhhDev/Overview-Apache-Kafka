# üìò Overview-Apache-Kafka

## üß≠ Conceitos Fundamentais

### üü¢ Produtor e Consumidor
- Kafka atua como **intermedi√°rio** entre **Producer** (produtor) e **Consumer** (consumidor).

` producer --> Kafka <-- consumer `

- Kafka **n√£o envia** nem **distribui** mensagens. Ele apenas **armazena**.
- O **Consumer** √© quem vai at√© o Kafka e **l√™** a mensagem.
- Kafka funciona em um **cluster** (conjunto de m√°quinas), formado por **n√≥s** chamados de **brokers**.

> üî∏ Recomenda√ß√£o m√≠nima: **3 brokers**

## üõ†Ô∏è Zookeeper
- Necess√°rio para o **gerenciamento e monitoramento** dos n√≥s do Kafka.
- Garante a **orquestra√ß√£o e lideran√ßa** dos brokers.

## üß© T√≥picos
- Canal de comunica√ß√£o usado para **receber e disponibilizar dados**.
- Funciona como um **log particionado e persistente**.

`producer --(t√≥pico)--> Kafka <--(t√≥pico)-- consumer`

### Estrutura do Registro (Mensagem)
- Cada mensagem tem:
  - **Offset** (ID incremental por parti√ß√£o)
  - **Headers**
  - **Key**
  - **Value**
  - **Timestamp**

## üß± Parti√ß√µes
- Cada **t√≥pico** pode ter uma ou mais **parti√ß√µes**, garantindo:
  - **Distribui√ß√£o de carga**
  - **Resili√™ncia**

```
T√≥pico
‚îú‚îÄ‚îÄ Parti√ß√£o 1 --> mensagem A (offset 0)
‚îú‚îÄ‚îÄ Parti√ß√£o 2 --> mensagem B (offset 0)
‚îî‚îÄ‚îÄ Parti√ß√£o 3 --> mensagem C (offset 0)
```
## üóùÔ∏è Uso de Keys
- A **Key** define **em qual parti√ß√£o** a mensagem ser√° enviada.
- √ötil para garantir **ordem**:
  - Mensagens com a mesma Key v√£o sempre para a **mesma parti√ß√£o**.

### Exemplo pr√°tico:
- üí≥ Transfer√™ncia banc√°ria (offset 0 da parti√ß√£o 1)
- üßæ Estorno (offset 0 da parti√ß√£o 2)

> Problema: estorno pode ser processado **antes** da transfer√™ncia.

üîë **Solu√ß√£o**: Usar a **mesma Key** para garantir a **ordem** entre transfer√™ncia e estorno.

## üõ°Ô∏è Replica√ß√£o e Resili√™ncia
- **Replication Factor** define o n√∫mero de **c√≥pias** de cada parti√ß√£o.
  - Exemplo: fator 2 ‚áí cada parti√ß√£o ter√° **2 r√©plicas**.
- Garante alta **disponibilidade** em caso de falha de um broker.

### üè∑Ô∏è Lideran√ßa de Parti√ß√£o
- Cada parti√ß√£o tem um **l√≠der** (em um broker), respons√°vel por leitura e escrita.
- Se o l√≠der falhar, o Kafka elege um **novo l√≠der** automaticamente.

## üì¶ Garantia de Entrega (Producer)

### Tipos de `acks`:

| Tipo de ack      | Comportamento             | Garantia        | Desempenho |
|------------------|---------------------------|------------------|-------------|
| `acks=0`         | N√£o aguarda resposta      | Nenhuma         | üöÄ Alta     |
| `acks=1`         | Aguarda s√≥ do l√≠der       | Parcial         | ‚ö° M√©dia    |
| `acks=all / -1`  | Aguarda l√≠der e r√©plicas  | Total           | üê¢ Baixa    |

## üìä Modelos de Entrega

| Modelo             | Caracter√≠stica               | Risco                    |
|--------------------|------------------------------|--------------------------|
| **At most once**   | Melhor performance           | Pode perder mensagens    |
| **At least once**  | Entrega garantida            | Pode duplicar mensagens  |
| **Exactly once**   | Entrega √∫nica garantida      | Performance mais lenta   |

## üåÄ Idempot√™ncia
- Garante que **mensagens duplicadas** n√£o sejam processadas mais de uma vez.
- Kafka detecta e **descarta duplicatas**.
- √ötil em falhas de conex√£o e reenvios autom√°ticos pelo producer.


## üë• Consumidores e Parti√ß√µes

- Podemos ter cen√°rios como:
`1 Consumer --> 3 Parti√ß√µes`


- Tamb√©m √© poss√≠vel usar **Consumer Groups** (grupos de consumidores):
  - Cada **grupo** pode ser, por exemplo, uma **inst√¢ncia do mesmo sistema** rodando em diferentes m√°quinas.
  - Exemplo:
```
Grupo X:
‚îú‚îÄ‚îÄ Consumer A ‚Üí l√™ Parti√ß√µes 0 e 1
‚îî‚îÄ‚îÄ Consumer B ‚Üí l√™ Parti√ß√£o 2
```


> ‚ö†Ô∏è **Regra importante**: Dois **consumidores do mesmo grupo** **n√£o podem** ler a **mesma parti√ß√£o** ao mesmo tempo.

- Um **Consumer fora de grupo** (isolado) ir√° **ler todas as parti√ß√µes**, independentemente de divis√£o de carga.

---

## üê≥ Subindo o Apache Kafka com Docker Compose

Agora que entendemos os principais conceitos do Kafka, podemos subir um ambiente de testes com `docker-compose`.

### ‚úÖ Pr√©-requisitos

- Docker instalado ([instalar](https://docs.docker.com/get-docker/))
- Docker Compose instalado (caso necess√°rio, use `docker compose` com Docker Desktop)

### üìÅ Estrutura do Projeto

Crie um arquivo chamado `docker-compose.yml` com o seguinte conte√∫do:

```yaml
version: "3"

services:  

  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
    extra_hosts:
      - "host.docker.internal:172.17.0.1"

  kafka:
    image: confluentinc/cp-kafka:6.0.0
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
      - "9094:9094"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_INTER_BROKER_LISTENER_NAME: INTERNAL
      KAFKA_LISTENERS: INTERNAL://:9092,OUTSIDE://:9094
      KAFKA_ADVERTISED_LISTENERS: INTERNAL://kafka:9092,OUTSIDE://host.docker.internal:9094
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INTERNAL:PLAINTEXT,OUTSIDE:PLAINTEXT
    extra_hosts:
      - "host.docker.internal:172.17.0.1"

  control-center:
    image: confluentinc/cp-enterprise-control-center:6.0.0
    hostname: control-center
    depends_on:
      - kafka
    ports:
      - "9021:9021"
    environment:
      CONTROL_CENTER_BOOTSTRAP_SERVERS: 'kafka:9092'
      CONTROL_CENTER_REPLICATION_FACTOR: 1
      CONTROL_CENTER_CONNECT_CLUSTER: http://kafka-connect:8083
      PORT: 9021
    extra_hosts:
      - "host.docker.internal:172.17.0.1"
```

## üõ†Ô∏è Acessando e Utilizando o Kafka no Docker

Com nosso ambiente Docker instanciado, podemos acessar o terminal do container Kafka para realizar testes e comandos administrativos.

### ‚ñ∂Ô∏è Acessar o container

```bash
docker exec -it kafka bash
```
## üìÑComandos com kafka-topics
- Utilizado para criar, listar e descrever t√≥picos no Kafka.

###üîß Criar t√≥pico
` kafka-topics --create --topic teste --bootstrap-server localhost:9092 --partitions 3`

###üìú Listar t√≥picos
`kafka-topics --list --bootstrap-server=localhost:9092`

üîç Descrever t√≥pico
`kafka-topics --describe --topic=teste --bootstrap-server=localhost:9092`

Exemplo de sa√≠da:
```
Topic: teste  PartitionCount: 3  ReplicationFactor: 1  Configs:
  Topic: teste  Partition: 0  Leader: 1  Replicas: 1  Isr: 1
  Topic: teste  Partition: 1  Leader: 1  Replicas: 1  Isr: 1
  Topic: teste  Partition: 2  Leader: 1  Replicas: 1  Isr: 1
```

‚úâÔ∏è Produzindo e Consumindo Mensagens
üì§ Enviar mensagens (Producer)
`kafka-console-producer --topic=teste --bootstrap-server=localhost:9092`

üì• Consumir mensagens (Consumer)
`kafka-console-consumer --topic=teste --bootstrap-server=localhost:9092`

üïì Ler mensagens desde o in√≠cio
`kafka-console-consumer --topic=teste --from-beginning --bootstrap-server=localhost:9092`

üî∏ Com --from-beginning, o consumidor ler√° todas as mensagens do t√≥pico, inclusive as anteriores √† conex√£o.
> ‚ö†Ô∏è As mensagens podem vir fora de ordem se n√£o houver key.

üë• Usando --group com Consumers
Para consumir de forma organizada e paralela em m√∫ltiplas inst√¢ncias, usamos consumer groups:

`kafka-console-consumer --topic=teste --bootstrap-server=localhost:9092 --group=x`

üìä Monitorar grupos de consumidores

`kafka-consumer-groups --bootstrap-server=localhost:9092 --group=x --describe`

Exemplo de sa√≠da:

```
GROUP  TOPIC  PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG  CONSUMER-ID      HOST          CLIENT-ID
x      teste  0          9               9               0    consumer-x-1...  192.168...    consumer-x-1
```

üåê Acesso Visual com Confluent Control Center
Se estiver utilizando a imagem da Confluent, acesse via navegador:

`http://localhost:9021`

Painel visual com overview do cluster
T√≥picos, consumidores, produ√ß√£o, m√©tricas, etc.
